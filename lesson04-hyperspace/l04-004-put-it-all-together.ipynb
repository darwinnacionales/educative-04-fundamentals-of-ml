{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d8e0bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0 => Loss: 1333.56666666666660603369\n",
      "Iteration    1 => Loss: 151.14311361881479456315\n",
      "Iteration    2 => Loss: 64.99460808656145616169\n",
      "Iteration    3 => Loss: 57.26915626621605781565\n",
      "Iteration    4 => Loss: 55.23298174669454851937\n",
      "Iteration    5 => Loss: 53.68246847367679919216\n",
      "Iteration    6 => Loss: 52.23968654565974389925\n",
      "Iteration    7 => Loss: 50.87204908750363330228\n",
      "Iteration    8 => Loss: 49.57213794415822860628\n",
      "Iteration    9 => Loss: 48.33478160934138401217\n",
      "Iteration 5000 => Loss: 6.89576133146784187034\n",
      "Iteration 10000 => Loss: 6.89576133146784187034\n",
      "Iteration 15000 => Loss: 6.89576133146784187034\n",
      "Iteration 20000 => Loss: 6.89576133146784187034\n",
      "Iteration 25000 => Loss: 6.89576133146784187034\n",
      "Iteration 30000 => Loss: 6.89576133146784187034\n",
      "Iteration 35000 => Loss: 6.89576133146784187034\n",
      "Iteration 40000 => Loss: 6.89576133146784187034\n",
      "Iteration 45000 => Loss: 6.89576133146784187034\n",
      "Iteration 49990 => Loss: 6.89576133146784187034\n",
      "Iteration 49991 => Loss: 6.89576133146784187034\n",
      "Iteration 49992 => Loss: 6.89576133146784187034\n",
      "Iteration 49993 => Loss: 6.89576133146784187034\n",
      "Iteration 49994 => Loss: 6.89576133146784187034\n",
      "Iteration 49995 => Loss: 6.89576133146784187034\n",
      "Iteration 49996 => Loss: 6.89576133146784187034\n",
      "Iteration 49997 => Loss: 6.89576133146784187034\n",
      "Iteration 49998 => Loss: 6.89576133146784187034\n",
      "Iteration 49999 => Loss: 6.89576133146784187034\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# computing the predictions\n",
    "def predict(X, w):\n",
    "    return np.matmul(X, w)\n",
    "\n",
    "# calculating the loss\n",
    "def loss(X, Y, w):\n",
    "    return np.average((predict(X, w) - Y) ** 2)\n",
    "\n",
    "# evaluating the gradient\n",
    "def gradient(X, Y, w):\n",
    "    return 2 * np.matmul(X.T, (predict(X, w) - Y)) / X.shape[0]\n",
    "\n",
    "# performing the training phase for our classifier\n",
    "def train(X, Y, iterations, lr):\n",
    "    w = np.zeros((X.shape[1], 1))\n",
    "    for i in range(iterations):\n",
    "        # Print first 10, last 10, and every 10% of total iterations\n",
    "        if (\n",
    "            i < 10 or\n",
    "            i >= iterations - 10 or\n",
    "            (iterations >= 20 and i % max(1, iterations // 10) == 0)\n",
    "        ):\n",
    "            print(\"Iteration %4d => Loss: %.20f\" % (i, loss(X, Y, w)))\n",
    "        w -= gradient(X, Y, w) * lr\n",
    "    return w\n",
    "\n",
    "# loading the data first and then training the classifier for 50,000 iteration\n",
    "x1, x2, x3, y = np.loadtxt(\"pizza_3_vars.txt\", skiprows=1, unpack=True)\n",
    "X = np.column_stack((x1, x2, x3))\n",
    "Y = y.reshape(-1, 1)\n",
    "w = train(X, Y, iterations=50000, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1246ff2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
